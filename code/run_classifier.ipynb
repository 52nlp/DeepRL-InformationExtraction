{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testEntities_crf='consolidated2/consolidated/dev+test+context.new.crf.p'\n",
    "trainEntities_crf='consolidated2/consolidated/train+context.new.crf.p'\n",
    "\n",
    "testEntities_ent='consolidated/dev+test+context.5.p'\n",
    "trainEntities_ent='consolidated/train+context.5.p'\n",
    "\n",
    "train_articles_crf, train_titles_crf, train_identifiers_crf, train_downloaded_articles_crf, \\\n",
    "TRAIN_ENTITIES_CRF, TRAIN_CONFIDENCES_CRF, TRAIN_COSINE_SIM_CRF, CONTEXT1_crf, CONTEXT2_crf = pickle.load(open(trainEntities_crf, \"rb\"))\n",
    "\n",
    "#load cached entities (speed up)\n",
    "train_articles, train_titles, train_identifiers, train_downloaded_articles, \\\n",
    "TRAIN_ENTITIES, TRAIN_CONFIDENCES, TRAIN_COSINE_SIM, CONTEXT1, CONTEXT2 = pickle.load(open(trainEntities_ent, \"rb\"))\n",
    "\n",
    "\n",
    "test_articles_crf, test_titles_crf, test_identifiers_crf, test_downloaded_articles_crf,\\\n",
    "TEST_ENTITIES_CRF, TEST_CONFIDENCES_CRF, TEST_COSINE_SIM_CRF, CONTEXT_crf, CONTEXT2_crf = pickle.load(open(testEntities_crf, \"rb\"))\n",
    "\n",
    "test_articles, test_titles, test_identifiers, test_downloaded_articles,\\\n",
    "TEST_ENTITIES, TEST_CONFIDENCES, TEST_COSINE_SIM, CONTEXT, CONTEXT2 = pickle.load(open(testEntities_ent, \"rb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as MaxEnt\n",
    "import copy\n",
    "import random\n",
    "import collections\n",
    "from itertools import izip\n",
    "import sys, json, pdb, pickle, operator, collections\n",
    "import predict2 as p\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "def dd():\n",
    "    return {}\n",
    "\n",
    "def ddd():\n",
    "    return collections.defaultdict(dd)\n",
    "\n",
    "class Classifier(object):\n",
    "\n",
    "    def __init__(self, TRAIN_ENTITIES, TRAIN_CONFIDENCES, TRAIN_COSINE_SIM,\\\n",
    "                 TEST_ENTITIES, TEST_CONFIDENCES, TEST_COSINE_SIM):\n",
    "        self.TRAIN_ENTITIES = TRAIN_ENTITIES\n",
    "        self.TRAIN_CONFIDENCES = TRAIN_CONFIDENCES\n",
    "        self.TRAIN_COSINE_SIM = TRAIN_COSINE_SIM\n",
    "\n",
    "        self.TEST_ENTITIES = TEST_ENTITIES\n",
    "        self.TEST_CONFIDENCES = TEST_CONFIDENCES\n",
    "        self.TEST_COSINE_SIM = TEST_COSINE_SIM\n",
    "\n",
    "        self.match_orig_feature = True\n",
    "        self.print_query_scores = False\n",
    "\n",
    "\n",
    "    def trainClassifier(self, train_identifiers):\n",
    "\n",
    "        classifier = MaxEnt()\n",
    "        X = []\n",
    "        Y = []\n",
    "        for article_index in range(len(self.TRAIN_ENTITIES)):\n",
    "            article = self.TRAIN_ENTITIES[article_index]\n",
    "            for query_index in range(len(article)):\n",
    "                query = article[query_index]\n",
    "                for supporting_article_index in range(1,len(query)):\n",
    "                    features = self.getFeatures(article_index, query_index, supporting_article_index, \\\n",
    "                                                self.TRAIN_ENTITIES, self.TRAIN_CONFIDENCES,self.TRAIN_COSINE_SIM, CONTEXT1)\n",
    "                    labels = self.getLabels(article_index, query_index, supporting_article_index, \\\n",
    "                                                self.TRAIN_ENTITIES, train_identifiers)\n",
    "                        \n",
    "                    for label in labels:                            \n",
    "                        X.append(features)\n",
    "                        Y.append(label)\n",
    "                assert( len(X) == len(Y))\n",
    "            \n",
    "\n",
    "        print \"Num training examples\", len(X)\n",
    "        print \"Dist of classes\", [sum([i == y for y in Y])*1./len(X) for i in range(6)]\n",
    "        classifier.fit(X,Y)\n",
    "            \n",
    "        return classifier\n",
    "\n",
    "    def predictEntities(self, classifier):\n",
    "        predictions = [0,0,0,0,0,0]\n",
    "        DECISIONS = copy.deepcopy(self.TEST_ENTITIES)\n",
    "        i = 0\n",
    "        for article_index in range(len(self.TEST_ENTITIES)):\n",
    "            article = self.TEST_ENTITIES[article_index]\n",
    "            for query_index in range(len(article)):\n",
    "                query = article[query_index]\n",
    "                for supporting_article_index in range(len(query)):\n",
    "                    if supporting_article_index == 0:\n",
    "                        DECISIONS[article_index][query_index]\\\n",
    "                            [supporting_article_index] = [1, 1, 1, 1]\n",
    "                        continue\n",
    "                    DECISIONS[article_index][query_index]\\\n",
    "                            [supporting_article_index] = [0, 0, 0, 0] \n",
    "\n",
    "                    features = self.getFeatures(article_index, query_index, supporting_article_index, self.TEST_ENTITIES, self.TEST_CONFIDENCES,\\\n",
    "                               self.TEST_COSINE_SIM, CONTEXT2)\n",
    "\n",
    "#                     assert len(features) == 41\n",
    "                    prediction = classifier.predict(features)[0]\n",
    "                    predictions[prediction] += 1\n",
    "                    if prediction < 4:\n",
    "                        DECISIONS[article_index][query_index]\\\n",
    "                            [supporting_article_index][prediction] = 1\n",
    "                    elif prediction == 4:\n",
    "                        DECISIONS[article_index][query_index]\\\n",
    "                            [supporting_article_index] = [1, 1, 1, 1]\n",
    "                    if i < 10:\n",
    "                        print DECISIONS[article_index][query_index]\\\n",
    "                            [supporting_article_index]\n",
    "                        i+= 1\n",
    "        print [p*1. / sum(predictions) for p in predictions]\n",
    "\n",
    "        return DECISIONS\n",
    "\n",
    "    #Run both Max Confidence and Majority Aggregation Schemes given the decisions\n",
    "    #Return the decided tag for each query\n",
    "    def aggregateResults(self, DECISIONS):\n",
    "        majority = []\n",
    "        max_conf = []\n",
    "        for article_index in range(len(self.TEST_ENTITIES)):\n",
    "            max_conf.append([])\n",
    "            majority.append([])\n",
    "            article = self.TEST_ENTITIES[article_index]\n",
    "            for query_index in range(len(article)):\n",
    "                max_conf[article_index].append([])\n",
    "                majority[article_index].append([])\n",
    "                query = article[query_index]\n",
    "                for entity_index in range(4):\n",
    "                    max_confidence = -1\n",
    "                    max_confidence_tag = ''\n",
    "                    tag_occurances = {}\n",
    "                    for supporting_article_index in range(len(query)):\n",
    "                        supporting_article = query[supporting_article_index]\n",
    "                        if DECISIONS[article_index][query_index][supporting_article_index]\\\n",
    "                           [entity_index] == 0:\n",
    "                            continue\n",
    "\n",
    "\n",
    "                        confidence = self.TEST_CONFIDENCES[article_index][query_index]\\\n",
    "                                [supporting_article_index][entity_index]\n",
    "                        entity = supporting_article[entity_index].strip().lower()\n",
    "#                         assert(not entity == '')\n",
    "\n",
    "                        ##Update counts of majority\n",
    "                        if entity not in tag_occurances:\n",
    "                            tag_occurances[entity] = 1\n",
    "                        else:\n",
    "                            tag_occurances[entity] += 1\n",
    "\n",
    "                        ##Update max_confidence\n",
    "                        if confidence > max_confidence:\n",
    "                            max_confidence = confidence\n",
    "                            max_confidence_tag = entity\n",
    "                    max_majority_count = -1\n",
    "                    majority_tag = ''\n",
    "                    for ent in tag_occurances:\n",
    "                        if tag_occurances[ent] > max_majority_count:\n",
    "                            max_majority_count = tag_occurances[ent]\n",
    "                            majority_tag = ent\n",
    "                    max_conf[article_index][query_index].append(max_confidence_tag)\n",
    "                    majority[article_index][query_index].append(majority_tag)\n",
    "\n",
    "        return majority, max_conf\n",
    "\n",
    "\n",
    "\n",
    "    def evaluateBaseline(self, predicted_identifiers, test_identifiers, COUNT_ZERO):\n",
    "        for entity_index in range(4):\n",
    "            num_queries = 5\n",
    "            predicted_correct = [0.] * num_queries\n",
    "            total_predicted   = [0.] * num_queries\n",
    "            total_gold        = [0.] * num_queries\n",
    "\n",
    "            for article_index in range(len(predicted_identifiers)):\n",
    "                ## TODO: Add classifier for selecting query index?\n",
    "                for query_index in range(len(predicted_identifiers[article_index])):        \n",
    "                    predicted = predicted_identifiers[article_index][query_index][entity_index].strip().lower()\n",
    "                    gold = test_identifiers[article_index][entity_index].strip().lower()\n",
    "                    if gold == '' or (not COUNT_ZERO and gold == 'zero'):\n",
    "                        continue\n",
    "\n",
    "\n",
    "                    #special handling for shooterName (lenient eval)\n",
    "                    if entity_index == 0:\n",
    "                        predicted = set(predicted.split('|'))\n",
    "                        gold = set(gold.split('|'))\n",
    "                        correct = gold.intersection(predicted)\n",
    "                        predicted_correct[query_index] += (1 if len(correct)>0 else 0)\n",
    "                        total_predicted[query_index] += 1\n",
    "                        total_gold[query_index] += 1 \n",
    "                    else:\n",
    "                        total_predicted[query_index] += 1\n",
    "                        if predicted == gold:\n",
    "                            predicted_correct[query_index] += 1\n",
    "                        total_gold[query_index] += 1\n",
    "\n",
    "\n",
    "            print \"Entity\", entity_index, \":\",\n",
    "            if sum(total_predicted) == 0 :\n",
    "                continue\n",
    "\n",
    "            if sum(predicted_correct) == 0 :\n",
    "                continue\n",
    "\n",
    "            if  self.print_query_scores:\n",
    "                print \"BEGINNING WITH PER QUERY SCORES\"\n",
    "\n",
    "                for query_index in range(num_queries):\n",
    "                    print \"*********************************************\"\n",
    "                    print\n",
    "                    print \"QUERY INDEX:\", query_index\n",
    "                    self.displayScore(predicted_correct[query_index], total_predicted[query_index],\\\n",
    "                                      total_gold[query_index])\n",
    "                    print\n",
    "                    print \"*********************************************\"\n",
    "                print \"NOW SHOWING SCORES AGGREGATED OVER ALL QUERRIES\"\n",
    "            self.displayScore(sum(predicted_correct), sum(total_predicted),sum(total_gold))\n",
    "\n",
    "    def displayScore(self, predicted_correct, total_predicted, total_gold):\n",
    "        precision = predicted_correct / total_predicted\n",
    "        recall = predicted_correct / total_gold\n",
    "        f1 = (2*precision*recall)/(precision+recall)\n",
    "        print \"PRECISION\", precision, \"RECALL\", recall, \"F1\", f1\n",
    "        print \"Total predicted\", total_predicted\n",
    "\n",
    "    def runExploratoryTests(self, DECISIONS, train_identifiers, test_identifiers):\n",
    "        print \"Exploring how many times gold entity is not in original document\"\n",
    "        count = collections.defaultdict(lambda:0.)\n",
    "        total_count = collections.defaultdict(lambda:0.)\n",
    "        for article_index in range(len(self.TRAIN_ENTITIES)):\n",
    "            article = self.TRAIN_ENTITIES[article_index]\n",
    "            for entity_index in range(4):\n",
    "                for query_index in range(len(article)):\n",
    "                    query = article[query_index]\n",
    "                    if query_index > 0: #not shooter\n",
    "                        orig_entity = query[0][entity_index].strip().lower()\n",
    "                        gold = train_identifiers[article_index][entity_index].strip().lower()\n",
    "                        for supp_index in range(len(query)):\n",
    "                            entity = query[supp_index][entity_index].strip().lower()\n",
    "                            if entity == gold:\n",
    "                                count[entity_index] += 1\n",
    "                            total_count[entity_index] +=1\n",
    "                    else:\n",
    "                        orig_entity = set(query[0][entity_index].strip().lower().split('|'))\n",
    "                        gold = set(train_identifiers[article_index][entity_index].strip().lower().split('|'))\n",
    "                        for supp_index in range(len(query)):\n",
    "                            entity = set(query[supp_index][entity_index].strip().lower().split('|'))\n",
    "                            if len(entity.intersection(gold)) > len(orig_entity.intersection(gold)):\n",
    "                                count[entity_index] += 1\n",
    "                            total_count[entity_index] +=1\n",
    "\n",
    "        print \"COUNT \", count\n",
    "        print \"TOTAL \", total_count\n",
    "        print \"Ratio\" , [a/b for a,b in izip(count.values(),total_count.values())]\n",
    "\n",
    "        print \"Exploring if classifier ever chooses not first entity\"\n",
    "        print \"Program will halt with assert if classifier chooses entity not in org document\"\n",
    "        ones = [0] * 4\n",
    "        ones_not_orig = [0] * 4\n",
    "        counts = [0] * 4\n",
    "        for entity_index in range(4):\n",
    "            for article_index in range(len(self.TEST_ENTITIES)):\n",
    "                article = self.TEST_ENTITIES[article_index]\n",
    "                for query_index in range(len(article)):\n",
    "                    query = article[query_index]\n",
    "                    orig_entity = query[0][entity_index].strip().lower()\n",
    "                    gold = test_identifiers[article_index][entity_index].strip().lower()\n",
    "                    for supp_index in range(len(query)):\n",
    "                        decision = DECISIONS[article_index][query_index][supp_index][entity_index]\n",
    "                        ones[entity_index] += decision\n",
    "                        counts[entity_index] += 1\n",
    "                        if decision == 1:\n",
    "                            entity = query[supp_index][entity_index].strip().lower()\n",
    "                            if entity != orig_entity:\n",
    "                                ones_not_orig[entity_index] += 1\n",
    "\n",
    "        print \"Ratio ones in prediction\", [ ones[x]*1. / counts[x] for x in range(4)]\n",
    "        print \"Ratio one not matching original entity in prediction\", [ ones_not_orig[x]*1. / counts[x] for x in range(4)]\n",
    "        print \"It does not\"\n",
    "\n",
    "\n",
    "    def trainAndEval(self, train_identifiers, test_identifiers, COUNT_ZERO):\n",
    "        classifier = self.trainClassifier(train_identifiers)\n",
    "        DECISIONS  = self.predictEntities(classifier)\n",
    "\n",
    "        debug = False\n",
    "        if debug:\n",
    "            self.runExploratoryTests(DECISIONS, train_identifiers, test_identifiers)\n",
    "            return\n",
    "\n",
    "        majority, max_conf = self.aggregateResults(DECISIONS)\n",
    "        print \"#############################################################\"\n",
    "        print \"Evaluation for Classifier baseline with MAJORITY aggregation\"\n",
    "        print\n",
    "        self.evaluateBaseline(majority, test_identifiers, COUNT_ZERO)\n",
    "\n",
    "        print\n",
    "        print \"#############################################################\"\n",
    "        print \"Evaluation for Classifier baseline with MAX CONFIDENCE aggregation\"\n",
    "        print\n",
    "        self.evaluateBaseline(max_conf, test_identifiers, COUNT_ZERO)\n",
    "        print\n",
    "        print \"#############################################################\"\n",
    "    \n",
    "    def getFeatures(self, article_index, query_index, supporting_article_index, entities, confidences, cosine_sim, context):        \n",
    "        features= []\n",
    "\n",
    "        #Construct feature vector for this sampled entity\n",
    "        original_confidence = confidences[article_index][query_index][0]\n",
    "        confidence = confidences[article_index][query_index][supporting_article_index]\n",
    "        \n",
    "        #One hot vector to show if entity matches orginal\n",
    "        original_entity = entities[article_index][query_index][0]\n",
    "        new_entity = entities[article_index][query_index][supporting_article_index]\n",
    "        match_features = []\n",
    "        for e_index in range(len(original_entity)):\n",
    "            if original_entity[e_index] == '':\n",
    "                match_features += [0, 1]\n",
    "            elif original_entity[e_index].strip().lower() == new_entity[e_index].strip().lower():\n",
    "                match_features += [1, 0]\n",
    "            else:\n",
    "                match_features += [0, 1]\n",
    "        \n",
    "        # Cosine sim array is shifted by one.\n",
    "        # Index 0 should be 1 as orig is same as itself.\n",
    "        tfidf = 1 if supporting_article_index == 0 else \\\n",
    "                cosine_sim[article_index]\\\n",
    "                [query_index][supporting_article_index - 1]\n",
    "\n",
    "#         features = original_confidence+ confidence + match_features + [tfidf]\n",
    "        features = original_confidence+ confidence  + [tfidf]\n",
    "\n",
    "        for c in context[article_index][query_index][supporting_article_index]:\n",
    "            features += c            \n",
    "#         assert len(features) == 41\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def getLabels(self, article_index, query_index, supporting_article_index, entities, identifier):\n",
    "        #Extract out label for this article (ie. is label correct)\n",
    "        labels = []\n",
    "        gold_entities = identifier[article_index]\n",
    "        new_entities      = entities[article_index][query_index][supporting_article_index]\n",
    "        \n",
    "        for ind in range(len(gold_entities)):\n",
    "            ent = new_entities[ind].lower().strip()\n",
    "            gold = gold_entities[ind].lower().strip()\n",
    "            if gold == \"\":\n",
    "                continue\n",
    "            if ent == \"\":\n",
    "                continue\n",
    "            \n",
    "            #special handling for shooterName (entity_index = 0)\n",
    "            if ind == 0:\n",
    "                new_person = set(ent.split('|'))\n",
    "                gold_person = set(gold.split('|'))\n",
    "                if len(new_person.intersection(gold_person)) > 0:\n",
    "                    labels.append(ind)\n",
    "            else:\n",
    "                if gold == ent:\n",
    "                    labels.append(ind)\n",
    "        if labels == [0, 1, 2, 3]:\n",
    "            labels = [4]\n",
    "        elif labels == []:\n",
    "            labels = [5]\n",
    "        \n",
    "        assert (len(labels) > 0)\n",
    "        return labels\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ENTITIES ['', 'one', 'four', 'phoenix']\n",
      "TEST ENTITIES CRF ['', 'one', 'four', '']\n",
      "GOLD ['', 'zero', 'five', 'Atlanta']\n",
      "$$$$$$$$$$$$$$\n",
      "size 292\n",
      "Num training examples 16077\n",
      "Dist of classes [0.04447347141879704, 0.35784039310816695, 0.19437706039684022, 0.1659513590844063, 0.012004727250108852, 0.22535298874168067]\n",
      "[0, 0, 1, 0]\n",
      "[0, 1, 0, 0]\n",
      "[0, 1, 0, 0]\n",
      "[0, 1, 0, 0]\n",
      "[0, 1, 0, 0]\n",
      "[0, 1, 0, 0]\n",
      "[0, 1, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0.004175101214574899, 0.43294534412955465, 0.07300101214574899, 0.038461538461538464, 0.00037955465587044535, 0.45103744939271256]\n",
      "#############################################################\n",
      "Evaluation for Classifier baseline with MAJORITY aggregation\n",
      "\n",
      "Entity 0 : PRECISION 0.452380952381 RECALL 0.452380952381 F1 0.452380952381\n",
      "Total predicted 210.0\n",
      "Entity 1 : PRECISION 0.687654320988 RECALL 0.687654320988 F1 0.687654320988\n",
      "Total predicted 810.0\n",
      "Entity 2 : PRECISION 0.684870848708 RECALL 0.684870848708 F1 0.684870848708\n",
      "Total predicted 1355.0\n",
      "Entity 3 : PRECISION 0.537671232877 RECALL 0.537671232877 F1 0.537671232877\n",
      "Total predicted 1460.0\n",
      "\n",
      "#############################################################\n",
      "Evaluation for Classifier baseline with MAX CONFIDENCE aggregation\n",
      "\n",
      "Entity 0 : PRECISION 0.452380952381 RECALL 0.452380952381 F1 0.452380952381\n",
      "Total predicted 210.0\n",
      "Entity 1 : PRECISION 0.696296296296 RECALL 0.696296296296 F1 0.696296296296\n",
      "Total predicted 810.0\n",
      "Entity 2 : PRECISION 0.673062730627 RECALL 0.673062730627 F1 0.673062730627\n",
      "Total predicted 1355.0\n",
      "Entity 3 : PRECISION 0.53698630137 RECALL 0.53698630137 F1 0.53698630137\n",
      "Total predicted 1460.0\n",
      "\n",
      "#############################################################\n"
     ]
    }
   ],
   "source": [
    "i = 12\n",
    "j = 0\n",
    "k = 2\n",
    "for i in [random.randint(0,len(TEST_ENTITIES_CRF))]:\n",
    "    print \"TEST ENTITIES\",     TEST_ENTITIES[i][j][k]\n",
    "    print \"TEST ENTITIES CRF\", TEST_ENTITIES_CRF[i][j][k]\n",
    "    print \"GOLD\"            , test_identifiers [i]\n",
    "    print \"$$$$$$$$$$$$$$\"\n",
    "\n",
    "\n",
    "verbose = False\n",
    "\n",
    "count_name = 0\n",
    "print \"size\", len(TEST_CONFIDENCES_CRF)\n",
    "\n",
    "for entity_ind in range(4):\n",
    "    entity_name = p.int2tags[entity_ind+1]\n",
    "    correct = 0\n",
    "    gold_num = 0\n",
    "    total = 0\n",
    "    for article_ind in range(len(TEST_ENTITIES_CRF)):\n",
    "        article = TEST_ENTITIES_CRF[article_ind]\n",
    "        gold_ent = test_identifiers[article_ind][entity_ind].strip().lower()\n",
    "        for query_ind in range(len(article)):\n",
    "            query = article[query_ind]\n",
    "#             for sup_ind in range(len(query)):\n",
    "                \n",
    "\n",
    "            sup = query[0]\n",
    "\n",
    "            ent = sup[entity_ind].strip().lower()\n",
    "            \n",
    "            if gold_ent == '' or (True and gold_ent == 'zero'):\n",
    "                    continue\n",
    "            if entity_ind == 0:\n",
    "                    gold_ent_set = set(gold_ent.split('|'))\n",
    "                    correct_int = gold_ent_set.intersection(ent)\n",
    "                    correct += (1 if len(correct_int)>0 else 0)\n",
    "                    if not ent == set(['']):\n",
    "                        count_name += 1\n",
    "#                         print \"ent\", ent\n",
    "#                         print \"gold\", gold_ent_set\n",
    "                    gold_num += 1\n",
    "                    total += 1\n",
    "            else:\n",
    "\n",
    "                if ent == gold_ent: \n",
    "                    correct += 1\n",
    "#                 else:\n",
    "#                     if not ent == 'zero':\n",
    "#                         print \"---------------\"\n",
    "#                         print \"GOLD\", gold_ent\n",
    "#                         print \"ENT\", ent\n",
    "                gold_num += 1\n",
    "                total   += 1\n",
    "#     if entity_ind == 1:\n",
    "#         continue\n",
    "    prec = correct*1./total\n",
    "    recall = correct*1./gold_num\n",
    "#     print entity_name\n",
    "#     print \"prec\", prec\n",
    "#     print 'recall', recall\n",
    "    f1 = 0\n",
    "    if not prec + recall == 0:\n",
    "        f1 = 2*(prec*recall)/(prec+recall)\n",
    "#     print\n",
    "#     print entity_name\n",
    "#     print \"prec\", prec, \"recall\", recall, \"f1:\" , f1\n",
    "            \n",
    "# baseline = Classifier(TRAIN_ENTITIES_CRF, TRAIN_CONFIDENCES_CRF, TRAIN_COSINE_SIM_CRF,\\\n",
    "#              TEST_ENTITIES_CRF, TEST_CONFIDENCES_CRF, TEST_COSINE_SIM_CRF)\n",
    "   \n",
    "baseline = Classifier(TRAIN_ENTITIES, TRAIN_CONFIDENCES, TRAIN_COSINE_SIM, \\\n",
    "                      TEST_ENTITIES, TEST_CONFIDENCES, TEST_COSINE_SIM)\n",
    "            \n",
    "\n",
    "baseline.trainAndEval(train_identifiers, test_identifiers, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print len(CONTEXT1[0][0][0][1])\n",
    "\n",
    "\n",
    "Entity 0 : PRECISION 0.142857142857 RECALL 0.142857142857 F1 0.142857142857\n",
    "Total predicted 210.0\n",
    "Entity 1 : PRECISION 0.501234567901 RECALL 0.501234567901 F1 0.501234567901\n",
    "Total predicted 810.0\n",
    "Entity 2 : PRECISION 0.287084870849 RECALL 0.287084870849 F1 0.287084870849\n",
    "Total predicted 1355.0\n",
    "Entity 3 : PRECISION 0.265068493151 RECALL 0.265068493151 F1 0.265068493151\n",
    "Total predicted 1460.0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
